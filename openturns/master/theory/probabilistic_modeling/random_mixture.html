
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Random Mixture: affine combination of independent univariate distributions &#8212; OpenTURNS  documentation</title>
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Meta modeling" href="../meta_modeling/meta_modeling.html" />
    <link rel="prev" title="Copulas" href="copulas.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="http://trac.openturns.org">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../meta_modeling/meta_modeling.html" title="Meta modeling"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Reference guide</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" accesskey="U">Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="copulas.html"
                        title="previous chapter">Copulas</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../meta_modeling/meta_modeling.html"
                        title="next chapter">Meta modeling</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/probabilistic_modeling/random_mixture.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="random-mixture-affine-combination-of-independent-univariate-distributions">
<h1>Random Mixture: affine combination of independent univariate distributions<a class="headerlink" href="#random-mixture-affine-combination-of-independent-univariate-distributions" title="Permalink to this headline">¶</a></h1>
<p>A multivariate random variable <img class="math" src="../../_images/math/b4d1a67d55d68c3f0afdabbb41f86fb00c03dfb5.svg" alt="\vect{Y}"/> may be defined as an
affine transform of <img class="math" src="../../_images/math/08e45b5b78dc9f9b9b0bb177ec4d7ad08054cc73.svg" alt="n"/> independent univariate random variable, as
follows:</p>
<div class="math" id="equation-randommixtureformula">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-randommixtureformula" title="Permalink to this equation">¶</a></span><img src="../../_images/math/64d38db8260c8a9dd50bdb6ebac4b55eda78ee4b.svg" alt="\displaystyle \vect{Y}=\vect{y}_0+\mat{M}\,\vect{X}"/></p>
</div><p>where <img class="math" src="../../_images/math/8a7772766f3bed2c188104244f23787994336a1f.svg" alt="\vect{y}_0\in\mathbb{R}^d"/> is a deterministic vector with
<img class="math" src="../../_images/math/eb06c1a29e8f7499dcb28f0c266b1cd41cbd5dc2.svg" alt="d\in\{1,2,3\}"/>, <img class="math" src="../../_images/math/25d9f0eb6fee061813dc048b64dbadab92cad096.svg" alt="\mat{M}\in\mathcal{M}_{d,n}(\mathbb{R})"/> a
deterministic matrix and <img class="math" src="../../_images/math/6f903a4a113256e8ca68041caf1dcf6a1ed173cf.svg" alt="(X_k)_{ 1 \leq k \leq n}"/> are some
independent univariate distributions.</p>
<p>In such a case, it is possible to evaluate directly the distribution of
<img class="math" src="../../_images/math/b4d1a67d55d68c3f0afdabbb41f86fb00c03dfb5.svg" alt="\vect{Y}"/> and then to ask <img class="math" src="../../_images/math/b4d1a67d55d68c3f0afdabbb41f86fb00c03dfb5.svg" alt="\vect{Y}"/> any request compatible
with a distribution: moments, probability and cumulative density
functions, quantiles (in dimension 1 only) …</p>
<p><strong>Evaluation of the probability density function of the Random Mixture</strong></p>
<p>As the univariate random variables <img class="math" src="../../_images/math/138f39d0c7d18f6de494e85102efc4d65d3c5f0d.svg" alt="X_i"/> are independent, the
characteristic function of <img class="math" src="../../_images/math/b4d1a67d55d68c3f0afdabbb41f86fb00c03dfb5.svg" alt="\vect{Y}"/>, denoted <img class="math" src="../../_images/math/d57022cbbbb88ca2b9f19c3742609f41aee92e01.svg" alt="\phi_Y"/>, is
easily defined from the characteristic function of <img class="math" src="../../_images/math/1fc142fba181c6b5948fb49028662f6570c69dfa.svg" alt="X_k"/> denoted
<img class="math" src="../../_images/math/bc25325f3e58ca168b871be132048f81ba3dd062.svg" alt="\phi_{X_k}"/> as follows :</p>
<div class="math">
<p><img src="../../_images/math/b445283795b0a15153e943cc7b6bf956bfee7371.svg" alt="\displaystyle \phi_Y(u_1,\hdots,u_d)=\prod_{j=1}^de^{iu_j{y_0}_j}\prod_{k=1}^n\phi_{X_k}((M^tu)_k), \mbox{  for } \vect{u}\in\mathbb{R}^d
    \label{CharactFuncY}"/></p>
</div><div class="line-block">
<div class="line">Once <img class="math" src="../../_images/math/d57022cbbbb88ca2b9f19c3742609f41aee92e01.svg" alt="\phi_Y"/> evaluated, it is possible to evaluate the
probability density function of <img class="math" src="../../_images/math/33370fc688190ccba52888ac09200225067b2610.svg" alt="Y"/>, denoted <img class="math" src="../../_images/math/957f9410c5417b3b79c3b43f2426ceaf332a373f.svg" alt="p_Y"/> :
several techniques are possible, as the inversion of the Fourier
transformation. This technique is not easy to implement.</div>
<div class="line">Another technique is used, based on the Poisson sum
formulation, defined as follows:</div>
</div>
<blockquote>
<div><div class="math" id="equation-poissonsum">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-poissonsum" title="Permalink to this equation">¶</a></span><img src="../../_images/math/c7c25e4028ac0dbb3350abab6b59ec8484a2d655.svg" alt="\displaystyle \sum_{j_1\in\mathbb{Z}}\hdots\sum_{j_d\in\mathbb{Z}} p_Y\left(y_1+\frac{2\pi j_1}{h_1},\hdots,y_d+\frac{2\pi j_d}{h_d}\right)=
     \prod_{j=1}^d \frac{h_j}{2*\pi}\sum_{k_1\in\mathbb{Z}}\hdots\sum_{k_d\in\mathbb{Z}}\phi\left(k_1h_1,\hdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">By fixing <img class="math" src="../../_images/math/7c74db096b1cf4606f11b655090f3e768065afd8.svg" alt="h_1,\hdots,h_d"/> small enough,
<img class="math" src="../../_images/math/8fe36744e4e46e37402de51eb9b9840efd4eec8d.svg" alt="\frac{2k\pi}{h_j} \approx +\infty"/> and
<img class="math" src="../../_images/math/66cfd8f97e5915b9a0ffa8ba5cbf1b89e16546a9.svg" alt="p_Y(\hdots,\frac{2k\pi}{h_j},\hdots) \approx 0"/> because of the
decreasing properties of <img class="math" src="../../_images/math/957f9410c5417b3b79c3b43f2426ceaf332a373f.svg" alt="p_Y"/>. Thus the nested sums of the left
term of <a class="reference internal" href="#equation-poissonsum">(2)</a> are reduced to the central term
<img class="math" src="../../_images/math/0bad074c6efdbafe82d21c63778f488c291fb92c.svg" alt="j_1=\hdots=j_d = 0"/>: the left term is approximatively equal to
<img class="math" src="../../_images/math/d34e3c462ae834de78ef532ecb13a9ad1b4572db.svg" alt="p_Y(y)"/>.</div>
<div class="line">Furthermore, the right term of <a class="reference internal" href="#equation-poissonsum">(2)</a> is a series which
converges very fast: only few terms of the series are enough to get
machine-precision accuracy. Let us note that the factors
<img class="math" src="../../_images/math/92878ee68ac85fc9c74a1e6c5ad5348c711ab03a.svg" alt="\phi_Y(k_1 h_1,\hdots,k_d,h_d)"/>, which are expensive to
evaluate, do not depend on <img class="math" src="../../_images/math/08f38bf886365ac2a02da24bbb515fd88366d96e.svg" alt="y"/> and are evaluated once only.</div>
</div>
<div class="line-block">
<div class="line">It is also possible to greatly improve the performance of the
algorithm by noticing that equation&nbsp; is linear between <img class="math" src="../../_images/math/957f9410c5417b3b79c3b43f2426ceaf332a373f.svg" alt="p_Y"/> and
<img class="math" src="../../_images/math/d57022cbbbb88ca2b9f19c3742609f41aee92e01.svg" alt="\phi_Y"/>. We denote <img class="math" src="../../_images/math/b165e7790d38781d300fc816f9cab743977164ee.svg" alt="q_Y"/> and <img class="math" src="../../_images/math/d1a52edf572342dad06141b6588de91c2f2d64d1.svg" alt="\psi_Y"/> respectively
the density and the characteristic function of the multivariate normal
distribution with the same mean <img class="math" src="../../_images/math/900d73bd13e885820ccee5ffffdc19a3c2778a4b.svg" alt="\vect{\mu}"/> and same covariance
matrix <img class="math" src="../../_images/math/ba6d81545d099fabf9dfa774e796609c6ab2d1fc.svg" alt="\vect{C}"/> as the random mixture. By applying this
multivariate normal distribution to the equation&nbsp;, we obtain by
subtraction:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/1974d70f68a03fcd4739aa683b91a1ec0601c619.svg" alt="\displaystyle  p_Y\left(y\right) = \sum_{j\in\mathbb{Z}^d} q_Y\left(y_1+\frac{2\pi j_1}{h_1},\cdots,y_d+\frac{2\pi j_d}{h_d}\right)+
  \frac{H}{2^d\pi^d}\sum_{|k_1|\leq N}\cdots\sum_{|k_d|\leq N} \delta_Y\left(k_1h_1,\cdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}
  \label{algoPoisson}"/></p>
</div></div></blockquote>
<p>where <img class="math" src="../../_images/math/e7de5a252baef58b293047e2af7a3c2469a8808d.svg" alt="H = h_1\times\cdots\times h_d"/>,
<img class="math" src="../../_images/math/2f29ffa921aa7f6b10576096b4448427307a447b.svg" alt="j=(j_1,\cdots,j_d)"/>, <img class="math" src="../../_images/math/aebf3cd261c84a215e134b7545219a876cbea031.svg" alt="\delta_Y:=\phi_Y - \psi_Y"/></p>
<div class="line-block">
<div class="line">In the case where <img class="math" src="../../_images/math/7f353853fe2f1897a57bf39f2d442fe69a01cd73.svg" alt="n \gg 1"/>, using the limit central theorem,
the law of <img class="math" src="../../_images/math/b4d1a67d55d68c3f0afdabbb41f86fb00c03dfb5.svg" alt="\vect{Y}"/> tends to the normal distribution density
<img class="math" src="../../_images/math/35746cf962b49b4f684e4910eb1090eeb276647a.svg" alt="q"/>, which will drastically reduce <img class="math" src="../../_images/math/88a3fb8919f35e0118ecff82c722e5f4dd91c84b.svg" alt="N"/>. The sum on
<img class="math" src="../../_images/math/35746cf962b49b4f684e4910eb1090eeb276647a.svg" alt="q"/> will become the most CPU-intensive part, because in the
general case we will have to keep more terms than the central one in
this sum, since the parameters <img class="math" src="../../_images/math/9a41385f987ad2150de9f3d4cdf4c66769bc71f8.svg" alt="h_1, \dots  h_d"/> were
calibrated with respect to <img class="math" src="../../_images/math/27434aeb6e4a6f0853282722d87e3eb12407ed80.svg" alt="p"/> and not <img class="math" src="../../_images/math/35746cf962b49b4f684e4910eb1090eeb276647a.svg" alt="q"/>.</div>
</div>
<p>The parameters <img class="math" src="../../_images/math/9a41385f987ad2150de9f3d4cdf4c66769bc71f8.svg" alt="h_1, \dots  h_d"/> are calibrated using the
following formula:</p>
<div class="math">
<p><img src="../../_images/math/ee2af5509d520911a99e37b5bc1bbde5ef18530c.svg" alt="\begin{aligned}
    h_\ell = \frac{2\pi}{(\beta+4\alpha)\sigma_\ell}
  \end{aligned}"/></p>
</div><p>where <img class="math" src="../../_images/math/fa77784f5bfc65acec8c9528d2f3274df79ede31.svg" alt="\sigma_\ell=\sqrt{\Cov{\vect{Y}}_{\ell,\ell}}"/> and
<img class="math" src="../../_images/math/7b7ebf7e62696ba8c12562a84512553143e94b56.svg" alt="\alpha"/>, <img class="math" src="../../_images/math/14af7a5e31ce522938ba14519ad11a0412b02516.svg" alt="\beta"/> are respectively the number of standard
deviations covered by the marginal distribution (<img class="math" src="../../_images/math/6e04fcc4479ccb78a6b21a71ce082c078947d2f1.svg" alt="\alpha=5"/> by
default) and <img class="math" src="../../_images/math/14af7a5e31ce522938ba14519ad11a0412b02516.svg" alt="\beta"/> the number of marginal deviations beyond
which the density is negligible (<img class="math" src="../../_images/math/1cbfd18f081ee3c0612fab3012bba66554f1e4fc.svg" alt="\beta=8.5"/> by default).</p>
<p>The <img class="math" src="../../_images/math/88a3fb8919f35e0118ecff82c722e5f4dd91c84b.svg" alt="N"/> parameter is dynamically calibrated: we start with
<img class="math" src="../../_images/math/81c079bf7821e799d791a50b6cdd5b14ae6e8586.svg" alt="N=8"/> then we double <img class="math" src="../../_images/math/88a3fb8919f35e0118ecff82c722e5f4dd91c84b.svg" alt="N"/> value until the total contribution
of the additional terms is negligible.</p>
<p><strong>Evaluation of the moments of the Random Mixture</strong></p>
<p>The relation <a class="reference internal" href="#equation-randommixtureformula">(1)</a> enables to evaluate all the
moments of the random mixture, if mathematically defined. For example,
we have:</p>
<div class="math">
<p><img src="../../_images/math/cfc7724ef8fb0b78c932d0f65db82cc3f1305db9.svg" alt="\left\{
\begin{array}{lcl}
  \Expect{\vect{Y}} &amp; = &amp; \vect{y_0} + \mat{M}\Expect{\vect{X}} \\
  \Cov{\vect{Y}} &amp; = &amp; \mat{M}\,\Cov{\vect{X}}\mat{M}^t
\end{array}\right\}"/></p>
</div><p><strong>Computation on a regular grid</strong></p>
<p>The interest is to compute the density function on a regular grid.
Purposes are to get an approximation quickly. The regular grid is of
form:</p>
<div class="math">
<p><img src="../../_images/math/03418ee9ebc2feae81c5cb176fe701dbfdbf386e.svg" alt="\begin{aligned}
    \forall r\in\{1,\hdots,d\},\forall m\in\{0,\hdots,M-1\},\:y_{r,m}=\mu_r+b\left(\frac{2m+1}{M} - 1\right)\sigma_r
  \end{aligned}"/></p>
</div><p>By denoting <img class="math" src="../../_images/math/9208f9d5b828ddc77a0fb781faf7ad220832d9a7.svg" alt="p_{m_1,\hdots,m_d}=p_{\vect{Y}}(y_{1,m_1},\hdots,y_{d,m_d})"/>:</p>
<div class="math">
<p><img src="../../_images/math/2044424ffa10b8d6d206a7527344e7e70176ee8c.svg" alt="\begin{aligned}
    p_{m_1,\hdots,m_d}= Q_{m_1,\hdots,m_d}+S_{m_1,\hdots,m_d}
  \end{aligned}"/></p>
</div><p>for which the term <img class="math" src="../../_images/math/c089be73043f230ee2f908e96bd804adf49eb57e.svg" alt="S_{m_1,\hdots,m_d}"/> is the most CPU
consuming. This term rewrites:</p>
<div class="math">
<p><img src="../../_images/math/871b8e8383c60b3bdede583495297d8169ff30d4.svg" alt="\begin{aligned}
  S_{m_1,\hdots,m_d}=&amp;\frac{H}{2^d\pi^d}\sum_{k_1=-N}^{N}\hdots\sum_{k_d=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right)
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \label{Eq:S}
  \end{aligned}"/></p>
</div><p>with:</p>
<div class="math">
<p><img src="../../_images/math/d34d78d14b4365b29d4bc3f77badcd026c2fb6f6.svg" alt="\begin{aligned}
    \delta\left(k_1h_1,\hdots,k_dh_d\right)&amp;=(\phi-\psi)\left(k_1h_1,\hdots,k_dh_d\right)\\
    E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^d k_jh_j\left(\mu_j+b\left(\frac{2m_j+1}{M}-1\right)\sigma_j\right)}
  \end{aligned}"/></p>
</div><p>The aim is to rewrite the previous expression as a <img class="math" src="../../_images/math/af8ad398de24d3755529da925c1973541741f828.svg" alt="d"/>- discrete
Fourier transform, in order to apply Fast Fourier Transform (<em>FFT</em>) for
its evaluation.</p>
<p>We set <img class="math" src="../../_images/math/e63010002dbb7dd00d48d40aa68c3e06d3b5b218.svg" alt="M=N"/> and
<img class="math" src="../../_images/math/b75394b1063aae808c3354349db68a6853857c2e.svg" alt="\forall j \in\{1,\hdots,d\},\: h_j=\frac{\pi}{b\sigma_j}"/> and
<img class="math" src="../../_images/math/a4a15db84eff4df70453c8bd14c48dccacbc2107.svg" alt="\tau_j=\frac{\mu_j}{b\sigma_j}"/>. For convenience, we introduce
the functions:</p>
<div class="math">
<p><img src="../../_images/math/f8bd2f42498e65a1ce3809ea223203b3919be076.svg" alt="f_j(k) = e^{-i\pi (k+1)\left(\tau_j-1+\frac{1}{N}\right)}"/></p>
</div><p>We use <img class="math" src="../../_images/math/e4ed00ae0549af10f1b61aa1be982dfca99b8595.svg" alt="k+1"/> instead of <img class="math" src="../../_images/math/4fdc6254dc3e018091042c0d2ec476a72b14588d.svg" alt="k"/> in this function to simplify
expressions below.</p>
<p>We obtain:</p>
<div class="math">
<p><img src="../../_images/math/e700de666538605615128364e3a687a1504656c8.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^{d} k_jh_jb\sigma_j\left(\frac{\mu_j}{b\sigma_j}+\frac{2m_j}{N}+\frac{1}{N}-1\right)}\notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)}e^{-i\pi\sum_{j=1}^{d} k_j\left(\tau_j-1+\frac{1}{N}\right)} \notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)} f_1(k_1-1) \times\hdots\times f_d(k_d-1) \label{Eq:E}
  \end{aligned}"/></p>
</div><p>For performance reasons, we want to use the discrete Fourier transform
with the following convention in dimension 1:</p>
<div class="math">
<p><img src="../../_images/math/17811a2736c3e5d6ccb8bf174014923e5f8848a5.svg" alt="A_m = \sum_{k=0}^{N-1} a_k e^{-2i\pi\frac{km}{N}}"/></p>
</div><p>which extension to dimensions 2 and 3 are respectively:</p>
<div class="math">
<p><img src="../../_images/math/bd39a510d311dc1ee5249dcde70ac1143a1ec451.svg" alt="A_{m,n} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1} a_{k,l} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}}\\"/></p>
</div><div class="math">
<p><img src="../../_images/math/c3bd6942e9bf2bc1fda36c3e98dfc7ff4f9ce07a.svg" alt="A_{m,n,p} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1}\sum_{s=0}^{N-1} a_{k,l,s} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}} e^{-2i\pi\frac{sp}{N}}"/></p>
</div><p>We decompose sums of&nbsp; on the interval <img class="math" src="../../_images/math/a91169440526e69b84299f220a3e3fe359e4543b.svg" alt="[-N,N]"/> into three parts:</p>
<div class="math">
<p><img src="../../_images/math/f10c19747bd0604e0be7c1b706e97bad7f330a2b.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
    = &amp; \sum_{k_j=-N}^{-1} \delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \notag\\
    &amp; + \delta\left(k_1h_1,\hdots,0,\hdots,k_dh_d\right) E_{m_1,\hdots,0,\hdots,m_d}(k_1,\hdots,0,\hdots,k_d) \notag\\
    &amp; + \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \label{Eq:decomposition-sum}
  \end{aligned}"/></p>
</div><p>If we already computed <img class="math" src="../../_images/math/b4a4b7fe94696ac1c9f37c936c284e34e903e157.svg" alt="E"/> for dimension <img class="math" src="../../_images/math/fbdbfb71edfeb630cea7675b90d514227d008b9c.svg" alt="d-1"/>, then the
middle term in this sum is trivial.</p>
<p>To compute the last sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/3621d3f4d9b04a094ba00a63e0e41342d326148b.svg" alt="k_j'=k_j-1"/>:</p>
<div class="math">
<p><img src="../../_images/math/6cce62b44441d097913dba70ec54a39931fa3d89.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation gives:</p>
<div class="math">
<p><img src="../../_images/math/ab5e72140041953f0983eb46eb1e82fd39d9fe14.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} +\frac{m_j}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)\notag\\
  &amp;=
      e^{-2i\pi\left(\frac{m_j}{N}\right)}
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus</p>
<div class="math">
<p><img src="../../_images/math/fb20db79d746bb2d608b3741d7b8ff1e54819944.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = e^{-2i\pi\left(\frac{m_j}{N}\right)} \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma+}
  \end{aligned}"/></p>
</div><p>To compute the first sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/1818f0466cdd46275ecf37cad0dc64ba7476bbc6.svg" alt="k_j'=N+k_j"/>:</p>
<div class="math">
<p><img src="../../_images/math/fabaf8152dc63a2da8855caccd41971fdbf319ec.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation&nbsp; gives:</p>
<div class="math">
<p><img src="../../_images/math/a51579ebadf8197b7e5d4b097433ed12976c7a13.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} -m_j\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j-1-N)\times\hdots\times f_d(k_d-1) \notag\\
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus:</p>
<div class="math">
<p><img src="../../_images/math/a67bde57d1a559d0b172e063cf8663b4a320c5e1.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma-}
  \end{aligned}"/></p>
</div><p>To summarize:</p>
<ol class="arabic simple">
<li>In order to compute sum from <img class="math" src="../../_images/math/80f8430aa76776f7b4ccf2463643469584e520aa.svg" alt="k_1=1"/> to <img class="math" src="../../_images/math/88a3fb8919f35e0118ecff82c722e5f4dd91c84b.svg" alt="N"/>, we multiply
by <img class="math" src="../../_images/math/a861e8252ba241014bf3e54befe823a9a9091a50.svg" alt="e^{-2i\pi\left(\frac{m_1}{N}\right)}"/> and consider
<img class="math" src="../../_images/math/fb7cdbf362796a750ec9c85301d145fc94543558.svg" alt="\delta((k_1+1)h,\hdots)f_1(k_1)"/></li>
<li>In order to compute sum from <img class="math" src="../../_images/math/03599ce521a72d30db538ff8ad5bf9d9225627df.svg" alt="k_1=-N"/> to <img class="math" src="../../_images/math/b3b1e9bac34e18d4c45e6bbcb288c9e362606ea3.svg" alt="-1"/>, we
consider <img class="math" src="../../_images/math/d035ba916ffc4bbaf09549b9dfe3fbc83e7f2562.svg" alt="\delta((k_1-N)h,\hdots)\overline{f}_1(N-1-k_1)"/></li>
</ol>
<div class="topic">
<p class="topic-title first">API:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../../user_manual/_generated/openturns.RandomMixture.html#openturns.RandomMixture" title="openturns.RandomMixture"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMixture</span></code></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li>See <span class="xref std std-doc">/examples/probabilistic_modeling/random_mixture_distribution</span></li>
<li>See <span class="xref std std-doc">/examples/probabilistic_modeling/random_mixture_distribution_discrete</span></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">References:</p>
<ul class="simple">
<li>Abate, J. and Whitt, W. (1992). <em>The Fourier-series method for inverting transforms of probability distributions</em>. Queueing Systems 10, 5–88., 1992, formula 5.5.</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../meta_modeling/meta_modeling.html" title="Meta modeling"
             >next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Reference guide</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" >Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2017 Airbus-EDF-IMACS-Phimeca.
      Last updated on Jan 01, 2017.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.0+.
    </div>
  </body>
</html>