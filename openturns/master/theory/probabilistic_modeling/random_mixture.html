
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Random Mixture: affine combination of independent univariate distributions &#8212; OpenTURNS  documentation</title>
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Meta modeling" href="../meta_modeling/meta_modeling.html" />
    <link rel="prev" title="Copulas" href="copulas.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="http://trac.openturns.org">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../meta_modeling/meta_modeling.html" title="Meta modeling"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Reference guide</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" accesskey="U">Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="copulas.html"
                        title="previous chapter">Copulas</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../meta_modeling/meta_modeling.html"
                        title="next chapter">Meta modeling</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/probabilistic_modeling/random_mixture.rst"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="random-mixture-affine-combination-of-independent-univariate-distributions">
<h1>Random Mixture: affine combination of independent univariate distributions<a class="headerlink" href="#random-mixture-affine-combination-of-independent-univariate-distributions" title="Permalink to this headline">¶</a></h1>
<p>A multivariate random variable <img class="math" src="../../_images/math/1ca0e315ae4eaf246041889d6a7ed57680d05c35.svg" alt="\vect{Y}"/> may be defined as an
affine transform of <img class="math" src="../../_images/math/3492afb5563cde1aa48c3366d238465a2fd06173.svg" alt="n"/> independent univariate random variable, as
follows:</p>
<div class="math" id="equation-randommixtureformula">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-randommixtureformula" title="Permalink to this equation">¶</a></span><img src="../../_images/math/619c6d62d53450026d359f22eaca9d1226164a20.svg" alt="\displaystyle \vect{Y}=\vect{y}_0+\mat{M}\,\vect{X}"/></p>
</div><p>where <img class="math" src="../../_images/math/e080d4982f40e9b05602acd2432aa09972ef50c5.svg" alt="\vect{y}_0\in\mathbb{R}^d"/> is a deterministic vector with
<img class="math" src="../../_images/math/d49927566427a2c76f29db1debccfb7603da52c1.svg" alt="d\in\{1,2,3\}"/>, <img class="math" src="../../_images/math/47326d68453b18f4c6c6e9cc80b7d925345c956c.svg" alt="\mat{M}\in\mathcal{M}_{d,n}(\mathbb{R})"/> a
deterministic matrix and <img class="math" src="../../_images/math/91675eaa17f8681fb9a7dab85407328a56273a4a.svg" alt="(X_k)_{ 1 \leq k \leq n}"/> are some
independent univariate distributions.</p>
<p>In such a case, it is possible to evaluate directly the distribution of
<img class="math" src="../../_images/math/1ca0e315ae4eaf246041889d6a7ed57680d05c35.svg" alt="\vect{Y}"/> and then to ask <img class="math" src="../../_images/math/1ca0e315ae4eaf246041889d6a7ed57680d05c35.svg" alt="\vect{Y}"/> any request compatible
with a distribution: moments, probability and cumulative density
functions, quantiles (in dimension 1 only) …</p>
<p><strong>Evaluation of the probability density function of the Random Mixture</strong></p>
<p>As the univariate random variables <img class="math" src="../../_images/math/b4350659c07de08817a1e30229c7e68f8d5818a5.svg" alt="X_i"/> are independent, the
characteristic function of <img class="math" src="../../_images/math/1ca0e315ae4eaf246041889d6a7ed57680d05c35.svg" alt="\vect{Y}"/>, denoted <img class="math" src="../../_images/math/b88af51e8db1dd490466ee5ebfd641bd63ef2520.svg" alt="\phi_Y"/>, is
easily defined from the characteristic function of <img class="math" src="../../_images/math/6cc26d80b4789982ec74cf3860065fb884953a95.svg" alt="X_k"/> denoted
<img class="math" src="../../_images/math/3489af7a94397d773bfae21cd8666688117b40d2.svg" alt="\phi_{X_k}"/> as follows :</p>
<div class="math">
<p><img src="../../_images/math/75d94ed70de133f59be8be7c1f0d86b555306c73.svg" alt="\displaystyle \phi_Y(u_1,\hdots,u_d)=\prod_{j=1}^de^{iu_j{y_0}_j}\prod_{k=1}^n\phi_{X_k}((M^tu)_k), \mbox{  for } \vect{u}\in\mathbb{R}^d
    \label{CharactFuncY}"/></p>
</div><div class="line-block">
<div class="line">Once <img class="math" src="../../_images/math/b88af51e8db1dd490466ee5ebfd641bd63ef2520.svg" alt="\phi_Y"/> evaluated, it is possible to evaluate the
probability density function of <img class="math" src="../../_images/math/19736b8b9764e1a2d2f06ea4084a9573802cba4c.svg" alt="Y"/>, denoted <img class="math" src="../../_images/math/d941630de3605ed9860602b6b967a9af622450aa.svg" alt="p_Y"/> :
several techniques are possible, as the inversion of the Fourier
transformation. This technique is not easy to implement.</div>
<div class="line">Another technique is used, based on the Poisson sum
formulation, defined as follows:</div>
</div>
<blockquote>
<div><div class="math" id="equation-poissonsum">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-poissonsum" title="Permalink to this equation">¶</a></span><img src="../../_images/math/7864b3f49fd3c7f367cf42b00eadd3e3c9ce08a8.svg" alt="\displaystyle \sum_{j_1\in\mathbb{Z}}\hdots\sum_{j_d\in\mathbb{Z}} p_Y\left(y_1+\frac{2\pi j_1}{h_1},\hdots,y_d+\frac{2\pi j_d}{h_d}\right)=
     \prod_{j=1}^d \frac{h_j}{2*\pi}\sum_{k_1\in\mathbb{Z}}\hdots\sum_{k_d\in\mathbb{Z}}\phi\left(k_1h_1,\hdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">By fixing <img class="math" src="../../_images/math/964e87b7f0abeb302872e1b2cd1d6467eedf8734.svg" alt="h_1,\hdots,h_d"/> small enough,
<img class="math" src="../../_images/math/1e078c792e26102d12fd4a8bda97ec0be47ba644.svg" alt="\frac{2k\pi}{h_j} \approx +\infty"/> and
<img class="math" src="../../_images/math/d5ec9a0e7995607542a4462f0aabed127d9fe697.svg" alt="p_Y(\hdots,\frac{2k\pi}{h_j},\hdots) \approx 0"/> because of the
decreasing properties of <img class="math" src="../../_images/math/d941630de3605ed9860602b6b967a9af622450aa.svg" alt="p_Y"/>. Thus the nested sums of the left
term of <a class="reference internal" href="#equation-poissonsum">(2)</a> are reduced to the central term
<img class="math" src="../../_images/math/5aded387139420e353b265cfb57bacb28c06e365.svg" alt="j_1=\hdots=j_d = 0"/>: the left term is approximatively equal to
<img class="math" src="../../_images/math/d607602984317f7b3c70ed02d4be1ee340ce596b.svg" alt="p_Y(y)"/>.</div>
<div class="line">Furthermore, the right term of <a class="reference internal" href="#equation-poissonsum">(2)</a> is a series which
converges very fast: only few terms of the series are enough to get
machine-precision accuracy. Let us note that the factors
<img class="math" src="../../_images/math/dc85e86f1317ac229aa5ce2465624e175cb6fc47.svg" alt="\phi_Y(k_1 h_1,\hdots,k_d,h_d)"/>, which are expensive to
evaluate, do not depend on <img class="math" src="../../_images/math/911a4ab2427f3b2a45f7b20c036b487cbad9c175.svg" alt="y"/> and are evaluated once only.</div>
</div>
<div class="line-block">
<div class="line">It is also possible to greatly improve the performance of the
algorithm by noticing that equation&nbsp; is linear between <img class="math" src="../../_images/math/d941630de3605ed9860602b6b967a9af622450aa.svg" alt="p_Y"/> and
<img class="math" src="../../_images/math/b88af51e8db1dd490466ee5ebfd641bd63ef2520.svg" alt="\phi_Y"/>. We denote <img class="math" src="../../_images/math/1a25dbac8dbc0c3bae26e9763b9a05dba7e15b12.svg" alt="q_Y"/> and <img class="math" src="../../_images/math/bd90afaed57dd8974b1196d128230c67026588e9.svg" alt="\psi_Y"/> respectively
the density and the characteristic function of the multivariate normal
distribution with the same mean <img class="math" src="../../_images/math/7155fa77403ab87ab11207cca0b5330da3a8425e.svg" alt="\vect{\mu}"/> and same covariance
matrix <img class="math" src="../../_images/math/fbdc34713672d4de8987c45899baebc4b301fd5f.svg" alt="\vect{C}"/> as the random mixture. By applying this
multivariate normal distribution to the equation&nbsp;, we obtain by
subtraction:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/e0ecb116121894273f8a67acb5ac092950b313df.svg" alt="\displaystyle  p_Y\left(y\right) = \sum_{j\in\mathbb{Z}^d} q_Y\left(y_1+\frac{2\pi j_1}{h_1},\cdots,y_d+\frac{2\pi j_d}{h_d}\right)+
  \frac{H}{2^d\pi^d}\sum_{|k_1|\leq N}\cdots\sum_{|k_d|\leq N} \delta_Y\left(k_1h_1,\cdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}
  \label{algoPoisson}"/></p>
</div></div></blockquote>
<p>where <img class="math" src="../../_images/math/934771ad4b2d877075199eba8c3884b86d5307c0.svg" alt="H = h_1\times\cdots\times h_d"/>,
<img class="math" src="../../_images/math/80c718a3ea9c4ce61ba918e8825ac5e8a039f214.svg" alt="j=(j_1,\cdots,j_d)"/>, <img class="math" src="../../_images/math/e3bb9c6107c33cec149d367bca66ba5eaa3e6915.svg" alt="\delta_Y:=\phi_Y - \psi_Y"/></p>
<div class="line-block">
<div class="line">In the case where <img class="math" src="../../_images/math/1835c0eea573e7d49aaf7de3546d71f1c16bc27a.svg" alt="n \gg 1"/>, using the limit central theorem,
the law of <img class="math" src="../../_images/math/1ca0e315ae4eaf246041889d6a7ed57680d05c35.svg" alt="\vect{Y}"/> tends to the normal distribution density
<img class="math" src="../../_images/math/d3ff3f8dc62e7ced97541233ffedabb887bc5bb9.svg" alt="q"/>, which will drastically reduce <img class="math" src="../../_images/math/590e62c4db8a892c9b9a0c6f58bb7e2f1ec99e9b.svg" alt="N"/>. The sum on
<img class="math" src="../../_images/math/d3ff3f8dc62e7ced97541233ffedabb887bc5bb9.svg" alt="q"/> will become the most CPU-intensive part, because in the
general case we will have to keep more terms than the central one in
this sum, since the parameters <img class="math" src="../../_images/math/1c80e68d76cc527754eb25fee63eace729a6c29a.svg" alt="h_1, \dots  h_d"/> were
calibrated with respect to <img class="math" src="../../_images/math/0f4c0791a2997f071572e3ee6a344919caea8e95.svg" alt="p"/> and not <img class="math" src="../../_images/math/d3ff3f8dc62e7ced97541233ffedabb887bc5bb9.svg" alt="q"/>.</div>
</div>
<p>The parameters <img class="math" src="../../_images/math/1c80e68d76cc527754eb25fee63eace729a6c29a.svg" alt="h_1, \dots  h_d"/> are calibrated using the
following formula:</p>
<div class="math">
<p><img src="../../_images/math/6c473d3d8cad71cd92dc3d79e345442f89d3c546.svg" alt="\begin{aligned}
    h_\ell = \frac{2\pi}{(\beta+4\alpha)\sigma_\ell}
  \end{aligned}"/></p>
</div><p>where <img class="math" src="../../_images/math/a80daea5d9e5bdf7f2d3ed93f92daf46b4ed27b9.svg" alt="\sigma_\ell=\sqrt{\Cov{\vect{Y}}_{\ell,\ell}}"/> and
<img class="math" src="../../_images/math/e00bdcfbfef394a10115af1348cf8b8e36c63615.svg" alt="\alpha"/>, <img class="math" src="../../_images/math/5a519ff21b7afd2a20b1dc119bfcd9e5ad50441f.svg" alt="\beta"/> are respectively the number of standard
deviations covered by the marginal distribution (<img class="math" src="../../_images/math/4f831722e1d865875016f7c28b76125161c1f9a1.svg" alt="\alpha=5"/> by
default) and <img class="math" src="../../_images/math/5a519ff21b7afd2a20b1dc119bfcd9e5ad50441f.svg" alt="\beta"/> the number of marginal deviations beyond
which the density is negligible (<img class="math" src="../../_images/math/709f567cd7a48cde5f3edc87afd59f6e7d2f6bb2.svg" alt="\beta=8.5"/> by default).</p>
<p>The <img class="math" src="../../_images/math/590e62c4db8a892c9b9a0c6f58bb7e2f1ec99e9b.svg" alt="N"/> parameter is dynamically calibrated: we start with
<img class="math" src="../../_images/math/31fa6b43e2f93166d779fde4275090fead91d9ac.svg" alt="N=8"/> then we double <img class="math" src="../../_images/math/590e62c4db8a892c9b9a0c6f58bb7e2f1ec99e9b.svg" alt="N"/> value until the total contribution
of the additional terms is negligible.</p>
<p><strong>Evaluation of the moments of the Random Mixture</strong></p>
<p>The relation <a class="reference internal" href="#equation-randommixtureformula">(1)</a> enables to evaluate all the
moments of the random mixture, if mathematically defined. For example,
we have:</p>
<div class="math">
<p><img src="../../_images/math/ef1ff3f6aa234727498f88bf7670e353c746a1d3.svg" alt="\left\{
\begin{array}{lcl}
  \Expect{\vect{Y}} &amp; = &amp; \vect{y_0} + \mat{M}\Expect{\vect{X}} \\
  \Cov{\vect{Y}} &amp; = &amp; \mat{M}\,\Cov{\vect{X}}\mat{M}^t
\end{array}\right\}"/></p>
</div><p><strong>Computation on a regular grid</strong></p>
<p>The interest is to compute the density function on a regular grid.
Purposes are to get an approximation quickly. The regular grid is of
form:</p>
<div class="math">
<p><img src="../../_images/math/9a0440976b776da5863195cc4fe81741a7ba6d2b.svg" alt="\begin{aligned}
    \forall r\in\{1,\hdots,d\},\forall m\in\{0,\hdots,M-1\},\:y_{r,m}=\mu_r+b\left(\frac{2m+1}{M} - 1\right)\sigma_r
  \end{aligned}"/></p>
</div><p>By denoting <img class="math" src="../../_images/math/57af37acf21c4631137f12ab0d872ea14938a040.svg" alt="p_{m_1,\hdots,m_d}=p_{\vect{Y}}(y_{1,m_1},\hdots,y_{d,m_d})"/>:</p>
<div class="math">
<p><img src="../../_images/math/2a1de6428f7ba9f6677ae8d98f82c5bb15e6524e.svg" alt="\begin{aligned}
    p_{m_1,\hdots,m_d}= Q_{m_1,\hdots,m_d}+S_{m_1,\hdots,m_d}
  \end{aligned}"/></p>
</div><p>for which the term <img class="math" src="../../_images/math/4069acb4e666a6d985891b135d26b7684751ce73.svg" alt="S_{m_1,\hdots,m_d}"/> is the most CPU
consuming. This term rewrites:</p>
<div class="math">
<p><img src="../../_images/math/889c93ea1ed394b3bc649898549342d5c5432649.svg" alt="\begin{aligned}
  S_{m_1,\hdots,m_d}=&amp;\frac{H}{2^d\pi^d}\sum_{k_1=-N}^{N}\hdots\sum_{k_d=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right)
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \label{Eq:S}
  \end{aligned}"/></p>
</div><p>with:</p>
<div class="math">
<p><img src="../../_images/math/a5929eb4eb330782bc4a5a2edb05a906cde8ac4d.svg" alt="\begin{aligned}
    \delta\left(k_1h_1,\hdots,k_dh_d\right)&amp;=(\phi-\psi)\left(k_1h_1,\hdots,k_dh_d\right)\\
    E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^d k_jh_j\left(\mu_j+b\left(\frac{2m_j+1}{M}-1\right)\sigma_j\right)}
  \end{aligned}"/></p>
</div><p>The aim is to rewrite the previous expression as a <img class="math" src="../../_images/math/5bedc75d546b74f5c8a9327c072c85fda0fd787f.svg" alt="d"/>- discrete
Fourier transform, in order to apply Fast Fourier Transform (<em>FFT</em>) for
its evaluation.</p>
<p>We set <img class="math" src="../../_images/math/0511945e3404ebc308fe09cfbff2fce658a0da61.svg" alt="M=N"/> and
<img class="math" src="../../_images/math/1298fa12d8ca09bb67c795f48772c14da9bdadd9.svg" alt="\forall j \in\{1,\hdots,d\},\: h_j=\frac{\pi}{b\sigma_j}"/> and
<img class="math" src="../../_images/math/7cf5195acb4b9f4d1f2aebce53b7f5ce87fac759.svg" alt="\tau_j=\frac{\mu_j}{b\sigma_j}"/>. For convenience, we introduce
the functions:</p>
<div class="math">
<p><img src="../../_images/math/0f3bb8f59c045429d138ff506fedbfaf3a7a6ab4.svg" alt="f_j(k) = e^{-i\pi (k+1)\left(\tau_j-1+\frac{1}{N}\right)}"/></p>
</div><p>We use <img class="math" src="../../_images/math/b9cc8236999985eeced9624a00451f7ebc42e2d6.svg" alt="k+1"/> instead of <img class="math" src="../../_images/math/25ccf3f81465c5f61677ee2819c658ad49ef800d.svg" alt="k"/> in this function to simplify
expressions below.</p>
<p>We obtain:</p>
<div class="math">
<p><img src="../../_images/math/6434faae29c3b3be67b070a6b181e17acde1498c.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^{d} k_jh_jb\sigma_j\left(\frac{\mu_j}{b\sigma_j}+\frac{2m_j}{N}+\frac{1}{N}-1\right)}\notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)}e^{-i\pi\sum_{j=1}^{d} k_j\left(\tau_j-1+\frac{1}{N}\right)} \notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)} f_1(k_1-1) \times\hdots\times f_d(k_d-1) \label{Eq:E}
  \end{aligned}"/></p>
</div><p>For performance reasons, we want to use the discrete Fourier transform
with the following convention in dimension 1:</p>
<div class="math">
<p><img src="../../_images/math/941f0502eb346fada012d6daf7f1424d76c01031.svg" alt="A_m = \sum_{k=0}^{N-1} a_k e^{-2i\pi\frac{km}{N}}"/></p>
</div><p>which extension to dimensions 2 and 3 are respectively:</p>
<div class="math">
<p><img src="../../_images/math/09553b890343575a3749a78b93c8e07cd4e91c9b.svg" alt="A_{m,n} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1} a_{k,l} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}}\\"/></p>
</div><div class="math">
<p><img src="../../_images/math/9cab0133071ee3d32ea9c17e3856d379ec84b008.svg" alt="A_{m,n,p} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1}\sum_{s=0}^{N-1} a_{k,l,s} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}} e^{-2i\pi\frac{sp}{N}}"/></p>
</div><p>We decompose sums of&nbsp; on the interval <img class="math" src="../../_images/math/bd5d9b5c8b22e2360a4b18c9bd31faa0e8b7ae8e.svg" alt="[-N,N]"/> into three parts:</p>
<div class="math">
<p><img src="../../_images/math/a4b3a6d6f01c378c0a432bb58d9d15638b5f06ae.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
    = &amp; \sum_{k_j=-N}^{-1} \delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \notag\\
    &amp; + \delta\left(k_1h_1,\hdots,0,\hdots,k_dh_d\right) E_{m_1,\hdots,0,\hdots,m_d}(k_1,\hdots,0,\hdots,k_d) \notag\\
    &amp; + \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \label{Eq:decomposition-sum}
  \end{aligned}"/></p>
</div><p>If we already computed <img class="math" src="../../_images/math/000f3b0a1812a5044910c90225ec6f6e8f27ec5e.svg" alt="E"/> for dimension <img class="math" src="../../_images/math/9b29e677ca36ca22e97bcd1ade8fd42f6647d2ef.svg" alt="d-1"/>, then the
middle term in this sum is trivial.</p>
<p>To compute the last sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/559a833285f53c2b7f09a233abbfe11e1b78f4d5.svg" alt="k_j'=k_j-1"/>:</p>
<div class="math">
<p><img src="../../_images/math/4b715bc6765366bbd7fd3fb8adb9eddf03893d37.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation gives:</p>
<div class="math">
<p><img src="../../_images/math/7027629a7f893b6789d09eb375fce87db3837aff.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} +\frac{m_j}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)\notag\\
  &amp;=
      e^{-2i\pi\left(\frac{m_j}{N}\right)}
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus</p>
<div class="math">
<p><img src="../../_images/math/b987c4c2ec856b2749fe3d17b85369435b3406e9.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = e^{-2i\pi\left(\frac{m_j}{N}\right)} \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma+}
  \end{aligned}"/></p>
</div><p>To compute the first sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/c579794082bb3693c15a1ebc4e42c92e3caba45d.svg" alt="k_j'=N+k_j"/>:</p>
<div class="math">
<p><img src="../../_images/math/e40a404421739f30cbdc0a9e35674862ba19267d.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation&nbsp; gives:</p>
<div class="math">
<p><img src="../../_images/math/f2ca27ec3a0a42280f1f19cbf515429885757619.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} -m_j\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j-1-N)\times\hdots\times f_d(k_d-1) \notag\\
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus:</p>
<div class="math">
<p><img src="../../_images/math/0881b1cf826d7b45798e7ca8f83529e87e453ea4.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma-}
  \end{aligned}"/></p>
</div><p>To summarize:</p>
<ol class="arabic simple">
<li>In order to compute sum from <img class="math" src="../../_images/math/104b25db26d618b3d28efc7174b641f0ba73fbad.svg" alt="k_1=1"/> to <img class="math" src="../../_images/math/590e62c4db8a892c9b9a0c6f58bb7e2f1ec99e9b.svg" alt="N"/>, we multiply
by <img class="math" src="../../_images/math/4c5e3d16719a2758b772a8afe039801495f5b4c7.svg" alt="e^{-2i\pi\left(\frac{m_1}{N}\right)}"/> and consider
<img class="math" src="../../_images/math/6d10b8da7c20c5b888a558c944769fb1f6d776d4.svg" alt="\delta((k_1+1)h,\hdots)f_1(k_1)"/></li>
<li>In order to compute sum from <img class="math" src="../../_images/math/257e05b93cd4772c95e114534a7cba1bbe353adf.svg" alt="k_1=-N"/> to <img class="math" src="../../_images/math/29d504227317e53b76361db24900f0feb10c4ba9.svg" alt="-1"/>, we
consider <img class="math" src="../../_images/math/00063ee18189705616b00690473e2f544577c9cb.svg" alt="\delta((k_1-N)h,\hdots)\overline{f}_1(N-1-k_1)"/></li>
</ol>
<div class="topic">
<p class="topic-title first">API:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../../user_manual/_generated/openturns.RandomMixture.html#openturns.RandomMixture" title="openturns.RandomMixture"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMixture</span></code></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../../examples/probabilistic_modeling/random_mixture_distribution.html"><span class="doc">Create a random mixture of distributions</span></a></li>
<li>See <a class="reference internal" href="../../examples/probabilistic_modeling/random_mixture_distribution_discrete.html"><span class="doc">Create a discrete random mixture</span></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">References:</p>
<ul class="simple">
<li>Abate, J. and Whitt, W. (1992). <em>The Fourier-series method for inverting transforms of probability distributions</em>. Queueing Systems 10, 5–88., 1992, formula 5.5.</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../meta_modeling/meta_modeling.html" title="Meta modeling"
             >next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Reference guide</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" >Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2018 Airbus-EDF-IMACS-Phimeca.
      Last updated on Jan 01, 2018.
    </div>
  </body>
</html>