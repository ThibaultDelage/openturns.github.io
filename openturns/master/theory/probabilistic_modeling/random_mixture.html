
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Random Mixture: affine combination of independent univariate distributions &#8212; OpenTURNS  documentation</title>
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Stochastic process definitions" href="process_definitions.html" />
    <link rel="prev" title="Copulas" href="copulas.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="process_definitions.html" title="Stochastic process definitions"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" accesskey="U">Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="copulas.html"
                        title="previous chapter">Copulas</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="process_definitions.html"
                        title="next chapter">Stochastic process definitions</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/probabilistic_modeling/random_mixture.rst"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="random-mixture-affine-combination-of-independent-univariate-distributions">
<span id="random-mixture"></span><h1>Random Mixture: affine combination of independent univariate distributions<a class="headerlink" href="#random-mixture-affine-combination-of-independent-univariate-distributions" title="Permalink to this headline">¶</a></h1>
<p>A multivariate random variable <img class="math" src="../../_images/math/08e2dd88c947c17551cdad4317eadfbe6755e04d.svg" alt="\vect{Y}"/> may be defined as an
affine transform of <img class="math" src="../../_images/math/6fb2b89b4e2a226a36018528a6aa0265cb2f8946.svg" alt="n"/> independent univariate random variable, as
follows:</p>
<div class="math" id="equation-randommixtureformula">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-randommixtureformula" title="Permalink to this equation">¶</a></span><img src="../../_images/math/fa65d8fa0404c75bb1798db2ab2269318b6d3aab.svg" alt="\displaystyle \vect{Y}=\vect{y}_0+\mat{M}\,\vect{X}"/></p>
</div><p>where <img class="math" src="../../_images/math/9a09139e7444c46375d9c6436b907c01a0aee0da.svg" alt="\vect{y}_0\in\mathbb{R}^d"/> is a deterministic vector with
<img class="math" src="../../_images/math/3ef715c2973fb62ee9d2142824949ab5d4ad0aa5.svg" alt="d\in\{1,2,3\}"/>, <img class="math" src="../../_images/math/5160c95ddde627cc2ef6b21970680979b5c25499.svg" alt="\mat{M}\in\mathcal{M}_{d,n}(\mathbb{R})"/> a
deterministic matrix and <img class="math" src="../../_images/math/ddbfb400d0d6a0af61857d386b08be511254fa89.svg" alt="(X_k)_{ 1 \leq k \leq n}"/> are some
independent univariate distributions.</p>
<p>In such a case, it is possible to evaluate directly the distribution of
<img class="math" src="../../_images/math/08e2dd88c947c17551cdad4317eadfbe6755e04d.svg" alt="\vect{Y}"/> and then to ask <img class="math" src="../../_images/math/08e2dd88c947c17551cdad4317eadfbe6755e04d.svg" alt="\vect{Y}"/> any request compatible
with a distribution: moments, probability and cumulative density
functions, quantiles (in dimension 1 only) …</p>
<p><strong>Evaluation of the probability density function of the Random Mixture</strong></p>
<p>As the univariate random variables <img class="math" src="../../_images/math/ba161830a9dc7bd77b7029409e6f0f6985052709.svg" alt="X_i"/> are independent, the
characteristic function of <img class="math" src="../../_images/math/08e2dd88c947c17551cdad4317eadfbe6755e04d.svg" alt="\vect{Y}"/>, denoted <img class="math" src="../../_images/math/8715a1c74d3b82e3ef0a4a4ea22bc040db3661fb.svg" alt="\phi_Y"/>, is
easily defined from the characteristic function of <img class="math" src="../../_images/math/bdf84eeff7907ca5d77d60f1fced722501f26692.svg" alt="X_k"/> denoted
<img class="math" src="../../_images/math/0988741544358f67a27e7c7ce04d8973b5fba5e7.svg" alt="\phi_{X_k}"/> as follows :</p>
<div class="math" id="equation-charactfuncy">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-charactfuncy" title="Permalink to this equation">¶</a></span><img src="../../_images/math/898ce82b17cfd3fcb91ca9f458ac0fecb0e9f2fa.svg" alt="\displaystyle \phi_Y(u_1,\hdots,u_d)=\prod_{j=1}^de^{iu_j{y_0}_j}\prod_{k=1}^n\phi_{X_k}((M^tu)_k), \mbox{  for } \vect{u}\in\mathbb{R}^d"/></p>
</div><div class="line-block">
<div class="line">Once <img class="math" src="../../_images/math/8715a1c74d3b82e3ef0a4a4ea22bc040db3661fb.svg" alt="\phi_Y"/> evaluated, it is possible to evaluate the
probability density function of <img class="math" src="../../_images/math/007c922d3728af255acfd18d1e9c360ae028d713.svg" alt="Y"/>, denoted <img class="math" src="../../_images/math/ca0e817ec98151cafc539d1ef35e6d1b498229f7.svg" alt="p_Y"/> :
several techniques are possible, as the inversion of the Fourier
transformation. This technique is not easy to implement.</div>
<div class="line">Another technique is used, based on the Poisson sum
formulation, defined as follows:</div>
</div>
<blockquote>
<div><div class="math" id="equation-poissonsum">
<p><span class="eqno">(3)<a class="headerlink" href="#equation-poissonsum" title="Permalink to this equation">¶</a></span><img src="../../_images/math/80cd6473326c9c369727f5b9f7af808e3fa979dc.svg" alt="\displaystyle \sum_{j_1\in\mathbb{Z}}\hdots\sum_{j_d\in\mathbb{Z}} p_Y\left(y_1+\frac{2\pi j_1}{h_1},\hdots,y_d+\frac{2\pi j_d}{h_d}\right)=
     \prod_{j=1}^d \frac{h_j}{2*\pi}\sum_{k_1\in\mathbb{Z}}\hdots\sum_{k_d\in\mathbb{Z}}\phi\left(k_1h_1,\hdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">By fixing <img class="math" src="../../_images/math/4a36f84daa8a18b0c367b952d6f760e63884c2c1.svg" alt="h_1,\hdots,h_d"/> small enough,
<img class="math" src="../../_images/math/91289d0525b21cc045fe690022e3cc0c9b59ea2f.svg" alt="\frac{2k\pi}{h_j} \approx +\infty"/> and
<img class="math" src="../../_images/math/88396dba6168161529491deece449c6716cc2a29.svg" alt="p_Y(\hdots,\frac{2k\pi}{h_j},\hdots) \approx 0"/> because of the
decreasing properties of <img class="math" src="../../_images/math/ca0e817ec98151cafc539d1ef35e6d1b498229f7.svg" alt="p_Y"/>. Thus the nested sums of the left
term of <a class="reference internal" href="#equation-poissonsum">(3)</a> are reduced to the central term
<img class="math" src="../../_images/math/e93d1fe8ceab2d9828dbab17d4bb14c989a89863.svg" alt="j_1=\hdots=j_d = 0"/>: the left term is approximatively equal to
<img class="math" src="../../_images/math/8e1b0baedbe024ad7fcb47fc22176f8562377fff.svg" alt="p_Y(y)"/>.</div>
<div class="line">Furthermore, the right term of <a class="reference internal" href="#equation-poissonsum">(3)</a> is a series which
converges very fast: only few terms of the series are enough to get
machine-precision accuracy. Let us note that the factors
<img class="math" src="../../_images/math/f2c276e4d8dc7d16c60e3b0ff35972efbed60575.svg" alt="\phi_Y(k_1 h_1,\hdots,k_d,h_d)"/>, which are expensive to
evaluate, do not depend on <img class="math" src="../../_images/math/681f29e6f502f2b5bd5f256789636e99499f594f.svg" alt="y"/> and are evaluated once only.</div>
</div>
<div class="line-block">
<div class="line">It is also possible to greatly improve the performance of the
algorithm by noticing that equation  is linear between <img class="math" src="../../_images/math/ca0e817ec98151cafc539d1ef35e6d1b498229f7.svg" alt="p_Y"/> and
<img class="math" src="../../_images/math/8715a1c74d3b82e3ef0a4a4ea22bc040db3661fb.svg" alt="\phi_Y"/>. We denote <img class="math" src="../../_images/math/2616351ee3a44118819d3a6a474cca2ef59be7be.svg" alt="q_Y"/> and <img class="math" src="../../_images/math/0be9d29e7c7c4d0966ad166e8931c4640117fbb5.svg" alt="\psi_Y"/> respectively
the density and the characteristic function of the multivariate normal
distribution with the same mean <img class="math" src="../../_images/math/77160f4fd5da62df73b797cbea1f01dee7c7352f.svg" alt="\vect{\mu}"/> and same covariance
matrix <img class="math" src="../../_images/math/410e3ee7de9eeff400e8551973c1386e33195a94.svg" alt="\vect{C}"/> as the random mixture. By applying this
multivariate normal distribution to the equation , we obtain by
subtraction:</div>
</div>
<blockquote>
<div><div class="math" id="equation-algopoisson">
<p><span class="eqno">(4)<a class="headerlink" href="#equation-algopoisson" title="Permalink to this equation">¶</a></span><img src="../../_images/math/3d10ab1e658ab303f88a06cca3a569fb3bf5c6e9.svg" alt="\displaystyle  p_Y\left(y\right) = \sum_{j\in\mathbb{Z}^d} q_Y\left(y_1+\frac{2\pi j_1}{h_1},\cdots,y_d+\frac{2\pi j_d}{h_d}\right)+
   \frac{H}{2^d\pi^d}\sum_{|k_1|\leq N}\cdots\sum_{|k_d|\leq N} \delta_Y\left(k_1h_1,\cdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}"/></p>
</div></div></blockquote>
<p>where <img class="math" src="../../_images/math/49dd11c5a89e3f4638a3e7d507d2f9333b3886d0.svg" alt="H = h_1\times\cdots\times h_d"/>,
<img class="math" src="../../_images/math/0a30795fad95916c2ffed6045e8597b049f7215e.svg" alt="j=(j_1,\cdots,j_d)"/>, <img class="math" src="../../_images/math/bb49c11db76480b32111cdb88bde6c80713821f3.svg" alt="\delta_Y:=\phi_Y - \psi_Y"/></p>
<div class="line-block">
<div class="line">In the case where <img class="math" src="../../_images/math/3abb563e546bf7fc04a071d5b3d3b0e1fb593593.svg" alt="n \gg 1"/>, using the limit central theorem,
the law of <img class="math" src="../../_images/math/08e2dd88c947c17551cdad4317eadfbe6755e04d.svg" alt="\vect{Y}"/> tends to the normal distribution density
<img class="math" src="../../_images/math/b755e5095e35304df53eb04c4d02fba5cd990320.svg" alt="q"/>, which will drastically reduce <img class="math" src="../../_images/math/e5fa696008624bbb4544f764ae5cd7c73d4c7450.svg" alt="N"/>. The sum on
<img class="math" src="../../_images/math/b755e5095e35304df53eb04c4d02fba5cd990320.svg" alt="q"/> will become the most CPU-intensive part, because in the
general case we will have to keep more terms than the central one in
this sum, since the parameters <img class="math" src="../../_images/math/7833b71b89218481fedd574d9a740f77e7018d64.svg" alt="h_1, \dots  h_d"/> were
calibrated with respect to <img class="math" src="../../_images/math/0a51f74fdb12efb40f2b40e8036cbf0f13c8d667.svg" alt="p"/> and not <img class="math" src="../../_images/math/b755e5095e35304df53eb04c4d02fba5cd990320.svg" alt="q"/>.</div>
</div>
<p>The parameters <img class="math" src="../../_images/math/7833b71b89218481fedd574d9a740f77e7018d64.svg" alt="h_1, \dots  h_d"/> are calibrated using the
following formula:</p>
<div class="math">
<p><img src="../../_images/math/998a2a1b31965f6f24fa639fef3961b7fa7ffc1e.svg" alt="h_\ell = \frac{2\pi}{(\beta+4\alpha)\sigma_\ell}"/></p>
</div><p>where <img class="math" src="../../_images/math/62da1ad5491d62d729101c9e87784bfda4cedd0e.svg" alt="\sigma_\ell=\sqrt{\Cov{\vect{Y}}_{\ell,\ell}}"/> and
<img class="math" src="../../_images/math/76b5e485f3e9e29ec4dde654fb6b9d110213a6f5.svg" alt="\alpha"/>, <img class="math" src="../../_images/math/6cd04136b3bbd07d788c38ddbf25c2466dc04fe1.svg" alt="\beta"/> are respectively the number of standard
deviations covered by the marginal distribution (<img class="math" src="../../_images/math/3ed67777527177c8b9e5e223039b428c9251eb41.svg" alt="\alpha=5"/> by
default) and <img class="math" src="../../_images/math/6cd04136b3bbd07d788c38ddbf25c2466dc04fe1.svg" alt="\beta"/> the number of marginal deviations beyond
which the density is negligible (<img class="math" src="../../_images/math/0bdf118aaf08a47d7e3f085bb808ac6548b3af22.svg" alt="\beta=8.5"/> by default).</p>
<p>The <img class="math" src="../../_images/math/e5fa696008624bbb4544f764ae5cd7c73d4c7450.svg" alt="N"/> parameter is dynamically calibrated: we start with
<img class="math" src="../../_images/math/051fdeebc8fd429848b82c4d85c89ea6ec6305aa.svg" alt="N=8"/> then we double <img class="math" src="../../_images/math/e5fa696008624bbb4544f764ae5cd7c73d4c7450.svg" alt="N"/> value until the total contribution
of the additional terms is negligible.</p>
<p><strong>Evaluation of the moments of the Random Mixture</strong></p>
<p>The relation <a class="reference internal" href="#equation-randommixtureformula">(1)</a> enables to evaluate all the
moments of the random mixture, if mathematically defined. For example,
we have:</p>
<div class="math">
<p><img src="../../_images/math/6c88886bca2b8b6c77ad91dc9adf8d3f1c945a2d.svg" alt="\left\{
\begin{array}{lcl}
  \Expect{\vect{Y}} &amp; = &amp; \vect{y_0} + \mat{M}\Expect{\vect{X}} \\
  \Cov{\vect{Y}} &amp; = &amp; \mat{M}\,\Cov{\vect{X}}\mat{M}^t
\end{array}\right\}"/></p>
</div><p><strong>Computation on a regular grid</strong></p>
<p>The interest is to compute the density function on a regular grid.
Purposes are to get an approximation quickly. The regular grid is of
form:</p>
<div class="math">
<p><img src="../../_images/math/359ac892f83c7aba5c699b03711353bc298a41de.svg" alt="\begin{aligned}
    \forall r\in\{1,\hdots,d\},\forall m\in\{0,\hdots,M-1\},\:y_{r,m}=\mu_r+b\left(\frac{2m+1}{M} - 1\right)\sigma_r
  \end{aligned}"/></p>
</div><p>By denoting <img class="math" src="../../_images/math/4a971743097a7038368a5129830f08291b30922b.svg" alt="p_{m_1,\hdots,m_d}=p_{\vect{Y}}(y_{1,m_1},\hdots,y_{d,m_d})"/>:</p>
<div class="math">
<p><img src="../../_images/math/5c9a4eacb301bd85141acf0077755c2ce0fad93f.svg" alt="\begin{aligned}
    p_{m_1,\hdots,m_d}= Q_{m_1,\hdots,m_d}+S_{m_1,\hdots,m_d}
  \end{aligned}"/></p>
</div><p>for which the term <img class="math" src="../../_images/math/dd84e2aff55e8cbdcc235427c33c87465111825c.svg" alt="S_{m_1,\hdots,m_d}"/> is the most CPU
consuming. This term rewrites:</p>
<div class="math">
<p><img src="../../_images/math/91a63dfd5a4f530dc0662f14a4ad6ded10595f99.svg" alt="\begin{aligned}
  S_{m_1,\hdots,m_d}=&amp;\frac{H}{2^d\pi^d}\sum_{k_1=-N}^{N}\hdots\sum_{k_d=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right)
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \label{Eq:S}
  \end{aligned}"/></p>
</div><p>with:</p>
<div class="math">
<p><img src="../../_images/math/3ae1231ac5c38aa183a03a42e0854ca2484d74cb.svg" alt="\begin{aligned}
    \delta\left(k_1h_1,\hdots,k_dh_d\right)&amp;=(\phi-\psi)\left(k_1h_1,\hdots,k_dh_d\right)\\
    E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^d k_jh_j\left(\mu_j+b\left(\frac{2m_j+1}{M}-1\right)\sigma_j\right)}
  \end{aligned}"/></p>
</div><p>The aim is to rewrite the previous expression as a <img class="math" src="../../_images/math/7858bee94e5b7a103dd7f1dfcc179252e1647f16.svg" alt="d"/>- discrete
Fourier transform, in order to apply Fast Fourier Transform (<em>FFT</em>) for
its evaluation.</p>
<p>We set <img class="math" src="../../_images/math/6a7fb32ffd7aa48c9c4d7b8ad9441b691ce6eaf0.svg" alt="M=N"/> and
<img class="math" src="../../_images/math/5d708c0463c7d6b69b042b878bb53753b68a0af3.svg" alt="\forall j \in\{1,\hdots,d\},\: h_j=\frac{\pi}{b\sigma_j}"/> and
<img class="math" src="../../_images/math/3ca8978b73dd9232ccbb51085d3fb3ba0d971d69.svg" alt="\tau_j=\frac{\mu_j}{b\sigma_j}"/>. For convenience, we introduce
the functions:</p>
<div class="math">
<p><img src="../../_images/math/5b9f97761a049af6307faa5a2774330e31c3937a.svg" alt="f_j(k) = e^{-i\pi (k+1)\left(\tau_j-1+\frac{1}{N}\right)}"/></p>
</div><p>We use <img class="math" src="../../_images/math/b092fb207115b15339b9dc42683a667ca26ff51f.svg" alt="k+1"/> instead of <img class="math" src="../../_images/math/a3d2afe19489776a703d7832f19a676d23032d92.svg" alt="k"/> in this function to simplify
expressions below.</p>
<p>We obtain:</p>
<div class="math">
<p><img src="../../_images/math/b37121ca14966e54468c4eede90706a100b7bffb.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^{d} k_jh_jb\sigma_j\left(\frac{\mu_j}{b\sigma_j}+\frac{2m_j}{N}+\frac{1}{N}-1\right)}\notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)}e^{-i\pi\sum_{j=1}^{d} k_j\left(\tau_j-1+\frac{1}{N}\right)} \notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)} f_1(k_1-1) \times\hdots\times f_d(k_d-1) \label{Eq:E}
  \end{aligned}"/></p>
</div><p>For performance reasons, we want to use the discrete Fourier transform
with the following convention in dimension 1:</p>
<div class="math">
<p><img src="../../_images/math/421c55be365d8d5b7ca83de5444b5702115fc2a3.svg" alt="A_m = \sum_{k=0}^{N-1} a_k e^{-2i\pi\frac{km}{N}}"/></p>
</div><p>which extension to dimensions 2 and 3 are respectively:</p>
<div class="math">
<p><img src="../../_images/math/9d17198344e6528488a39a7e7f673cb368eb0fba.svg" alt="A_{m,n} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1} a_{k,l} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}}\\"/></p>
</div><div class="math">
<p><img src="../../_images/math/719f786978b50bedc1972b4b3194c462a7c016d2.svg" alt="A_{m,n,p} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1}\sum_{s=0}^{N-1} a_{k,l,s} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}} e^{-2i\pi\frac{sp}{N}}"/></p>
</div><p>We decompose sums of  on the interval <img class="math" src="../../_images/math/95675a5cf7687f7ff81578d06d877e7f9f9a66a5.svg" alt="[-N,N]"/> into three parts:</p>
<div class="math" id="equation-decomposition-sum">
<p><span class="eqno">(5)<a class="headerlink" href="#equation-decomposition-sum" title="Permalink to this equation">¶</a></span><img src="../../_images/math/26aa706765d475b9037fa36c281d67fdcbb59625.svg" alt="\begin{aligned}
    \sum_{k_j=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
      = &amp; \sum_{k_j=-N}^{-1} \delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \notag\\
      &amp; + \delta\left(k_1h_1,\hdots,0,\hdots,k_dh_d\right) E_{m_1,\hdots,0,\hdots,m_d}(k_1,\hdots,0,\hdots,k_d) \notag\\
      &amp; + \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
    \end{aligned}"/></p>
</div><p>If we already computed <img class="math" src="../../_images/math/ef6b5efbe5786c99109dd27043e2c9fc008982ef.svg" alt="E"/> for dimension <img class="math" src="../../_images/math/72f7d8c443e70c2775b9842af7f4f260f5fbea05.svg" alt="d-1"/>, then the
middle term in this sum is trivial.</p>
<p>To compute the last sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/15c193db0db460810b8e3149cc22e567ad519723.svg" alt="k_j'=k_j-1"/>:</p>
<div class="math">
<p><img src="../../_images/math/68d93406e3c1832df37c16e328c050faf66bc897.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation gives:</p>
<div class="math">
<p><img src="../../_images/math/b8b90e057ce14b66c19ba043d284f8dd96ee511b.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} +\frac{m_j}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)\notag\\
  &amp;=
      e^{-2i\pi\left(\frac{m_j}{N}\right)}
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus</p>
<div class="math">
<p><img src="../../_images/math/dc571b618b3c1f9eec5919abea14dc9c2c82841f.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = e^{-2i\pi\left(\frac{m_j}{N}\right)} \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma+}
  \end{aligned}"/></p>
</div><p>To compute the first sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/0337a26aef583ac58c2032e3da34435d9d33a130.svg" alt="k_j'=N+k_j"/>:</p>
<div class="math">
<p><img src="../../_images/math/c72029a8dc8a38717b7df6b6915649a7ad1825df.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation  gives:</p>
<div class="math">
<p><img src="../../_images/math/dca60f3d44fa11e04172f81b7c9ebc72889193f2.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} -m_j\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j-1-N)\times\hdots\times f_d(k_d-1) \notag\\
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus:</p>
<div class="math">
<p><img src="../../_images/math/fa8147557f93b728b255fb01805c9f923177aea7.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma-}
  \end{aligned}"/></p>
</div><p>To summarize:</p>
<ol class="arabic simple">
<li><p>In order to compute sum from <img class="math" src="../../_images/math/0350296adfc1f762e6248e285b6978dd8fc0d6b1.svg" alt="k_1=1"/> to <img class="math" src="../../_images/math/e5fa696008624bbb4544f764ae5cd7c73d4c7450.svg" alt="N"/>, we multiply
by <img class="math" src="../../_images/math/e8735c00001428b267112bbbca6d771042814ff9.svg" alt="e^{-2i\pi\left(\frac{m_1}{N}\right)}"/> and consider
<img class="math" src="../../_images/math/d52bf65ba88010f6d3f3f6263da076b6eceb284f.svg" alt="\delta((k_1+1)h,\hdots)f_1(k_1)"/></p></li>
<li><p>In order to compute sum from <img class="math" src="../../_images/math/ede283e87023722f11125a44cf7cee4d17751f58.svg" alt="k_1=-N"/> to <img class="math" src="../../_images/math/a1d1f94e4702c16c67231bfc56815c4a6b23851e.svg" alt="-1"/>, we
consider <img class="math" src="../../_images/math/63f22f153175bbc2b1ae52af9f6db23bed0dddae.svg" alt="\delta((k_1-N)h,\hdots)\overline{f}_1(N-1-k_1)"/></p></li>
</ol>
<div class="topic">
<p class="topic-title first">API:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../user_manual/_generated/openturns.RandomMixture.html#openturns.RandomMixture" title="openturns.RandomMixture"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMixture</span></code></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../examples/probabilistic_modeling/random_mixture_distribution.html"><span class="doc">Create a random mixture of distributions</span></a></p></li>
<li><p>See <a class="reference internal" href="../../examples/probabilistic_modeling/random_mixture_distribution_discrete.html"><span class="doc">Create a discrete random mixture</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">References:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../bibliography.html#abate1992" id="id1"><span>[abate1992]</span></a></p></li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="process_definitions.html" title="Stochastic process definitions"
             >next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" >Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2018 Airbus-EDF-IMACS-Phimeca.
      Last updated on Jan 01, 2018.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.0+/6e8f81df7.
    </div>
  </body>
</html>