
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Least squares problems numerical methods &#8212; OpenTURNS  documentation</title>
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Isoprobabilistic transformations" href="isoprobabilistic_transformation.html" />
    <link rel="prev" title="Optimization Algorithms" href="optimization_algorithm.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="http://trac.openturns.org">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="isoprobabilistic_transformation.html" title="Isoprobabilistic transformations"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="optimization_algorithm.html" title="Optimization Algorithms"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="numerical_methods.html" accesskey="U">Numerical methods</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="optimization_algorithm.html"
                        title="previous chapter">Optimization Algorithms</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="isoprobabilistic_transformation.html"
                        title="next chapter">Isoprobabilistic transformations</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/numerical_methods/least_squares.rst"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="least-squares-problems-numerical-methods">
<span id="least-squares"></span><h1>Least squares problems numerical methods<a class="headerlink" href="#least-squares-problems-numerical-methods" title="Permalink to this headline">Â¶</a></h1>
<div class="line-block">
<div class="line">This section presents numerical methods that can be used in order to
solve least squares problems, which can be encountered when the
construction of a <em>response surface</em> (i.e. of a meta-model) is of
interest, or when one wishes to perform a statistical regression.</div>
</div>
<div class="line-block">
<div class="line">Given a matrix <img class="math" src="../../_images/math/da82601f7c9786d263121f8636859c4af3df352c.svg" alt="\matr{\Psi}~\in~\Rset^{N\times P}"/>, <img class="math" src="../../_images/math/e4720ce5ee599ea57d29217e49f68279153c73c5.svg" alt="N&gt;P"/>,
and a vector <img class="math" src="../../_images/math/2a0445fb2b6a0ad13a621e278e77103a02b47aab.svg" alt="\underline{y}~\in~\Rset^{N}"/>, we want to find a
vector <img class="math" src="../../_images/math/1f2493e955dffa4af8908b180e5e25c19340546d.svg" alt="\underline{a}~\in \Rset^{P}"/> such that
<img class="math" src="../../_images/math/a82779d586ea416a80ac257b3b0c375cad8a2449.svg" alt="\matr{\Psi}\: \underline{a}"/> is the best approximation to
<img class="math" src="../../_images/math/5c28963d87c1e58fb272c9403c17fe3e9051ae4a.svg" alt="\underline{y}"/> in the least squares sense. Mathematically
speaking, we want to solve the following minimization problem:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/8a11e466414af352a06a217d9d1f6a39cf4e8cd0.svg" alt="\min_{\underline{a}} \, \, = \, \, \left\| \; \matr{\Psi} \, \underline{a} \, - \, \underline{y} \; \right\|_2"/></p>
</div><p>In the following, it is assumed that the rank of matrix
<img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/> is equal to <img class="math" src="../../_images/math/4c21bd0a8df01ae42f62d11fb29cb9ae23746161.svg" alt="P"/>.</p>
</div></blockquote>
<div class="line-block">
<div class="line">Several algorithms can be applied to compute the least squares
solution, as shown in the sequel.</div>
</div>
<p><strong>Method of normal equations</strong></p>
<div class="line-block">
<div class="line">It is shown that the solution of the least squares problem satisfies
the so-called <em>normal equations</em>, which read using a matrix notation:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/a59d52a30adf635b905eaa2ba39cb78aaf026b6e.svg" alt="\matr{\Psi}^{\mbox{\scriptsize \textsf{T}}} \; \matr{\Psi} \; \underline{a} \, \, = \, \, \matr{\Psi}^{\mbox{\scriptsize \textsf{T}}} \; \underline{y}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">The matrix
<img class="math" src="../../_images/math/b0b894776c1ed06c5e8a137c1797b1bc449dbe7e.svg" alt="\matr{C} \equiv \matr{\Psi}^{\mbox{\scriptsize \textsf{T}}} \; \matr{\Psi}"/>
is symmetric and positive definite. The system can be solved using the
following Cholesky factorization:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/576023f40e37859a65ddd8ee2d6503aa9b57bd3f.svg" alt="\matr{C} \, \, = \, \, \matr{R}^{\mbox{\scriptsize \textsf{T}}} \; \matr{R}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">where <img class="math" src="../../_images/math/9655901b77f9fa2145d534ce4ce71f6f179e48a0.svg" alt="\matr{R}"/> is an upper triangular matrix with positive
diagonal entries. Solving the normal equations is equivalent to
solving the two following triangular systems, which can be easily
solved by backwards substitution:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/f125c8d81b72b3035e507af5669d928117a1efa4.svg" alt="\begin{aligned}
    \matr{R}^{\mbox{\scriptsize \textsf{T}}} \; \underline{z} \, \, = \, \, \matr{\Psi}^{\mbox{\scriptsize \textsf{T}}} \; \underline{y}
    \qquad , \qquad \matr{R} \; \underline{a} \, \, = \, \, \underline{z}
  \end{aligned}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">It has to be noted that this theoretical approach is seldom used in
practice though. Indeed the resulting least squares solution is quite
sensitive to a small change in the data (i.e. in <img class="math" src="../../_images/math/5c28963d87c1e58fb272c9403c17fe3e9051ae4a.svg" alt="\underline{y}"/>
and <img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/>). More precisely, the normal equations are
always more badly conditioned than the original overdetermined system,
as their condition number is squared compared to the original problem:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/2d884aa8f9f78dc9307dbe36b05ac21cc9eec55c.svg" alt="\kappa(\matr{\Psi}^{\mbox{\scriptsize \textsf{T}}} \; \matr{\Psi}) \, \, = \, \, \kappa(\matr{\Psi})^2"/></p>
</div><p>As a consequence more robust numerical methods should be adopted.</p>
</div></blockquote>
<div class="line-block">
<div class="line"><strong>Method based on QR factorization</strong></div>
</div>
<div class="line-block">
<div class="line">It is shown that the matrix <img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/> can be factorized as
follows:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/120ac99adaa6162da1a05d35c78138433af5df13.svg" alt="\matr{\Psi} \, \, = \, \, \matr{Q} \; \matr{R}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">where <img class="math" src="../../_images/math/8186be6bbc35b81c07ba1712b27192fa1df64f4f.svg" alt="\matr{Q}"/> is a <img class="math" src="../../_images/math/590e62c4db8a892c9b9a0c6f58bb7e2f1ec99e9b.svg" alt="N"/>-by-<img class="math" src="../../_images/math/4c21bd0a8df01ae42f62d11fb29cb9ae23746161.svg" alt="P"/>-matrix with
<em>orthonormal</em> columns and <img class="math" src="../../_images/math/9655901b77f9fa2145d534ce4ce71f6f179e48a0.svg" alt="\matr{R}"/> is a
<img class="math" src="../../_images/math/4c21bd0a8df01ae42f62d11fb29cb9ae23746161.svg" alt="P"/>-by-<img class="math" src="../../_images/math/4c21bd0a8df01ae42f62d11fb29cb9ae23746161.svg" alt="P"/>-upper triangular matrix. Such a <em>QR
decomposition</em> may be constructed using several schemes, such as
<em>Gram-Schmidt orthogonalization</em>, <em>Householder reflections</em> or <em>Givens
rotations</em>.</div>
</div>
<div class="line-block">
<div class="line">In this setup the least squares problem is equivalent to solving:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/72918b9c520311645e98941f7c4ec323d5cbc7af.svg" alt="\matr{R} \; \underline{a} \, \, = \, \, \matr{Q}^{\mbox{\scriptsize \textsf{T}}} \; \underline{y}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">This upper triangular system can be solved using backwards
substitution.</div>
</div>
<div class="line-block">
<div class="line">The solving scheme based on Householder QR factorization leads to a
relative error that is proportional to:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/6043875d54c52a12dd97527786f5e2e42ff4d186.svg" alt="\kappa(\matr{\Psi}) + \|\underline{r}\|_2 \kappa(\matr{\Psi})^2"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">where
<img class="math" src="../../_images/math/7ee1afb5ffdd442cfc0988d1cb2e2f421f8bd6a7.svg" alt="\underline{r} = \matr{\Psi} \, \underline{a} \, - \, \underline{y}"/>.
Thus this error is expected to be much smaller than the one associated
with the normal equations provided that the residual
<img class="math" src="../../_images/math/cd1856b30a4f7b6b45dfa59cc3448d9e2b57ee0f.svg" alt="\underline{r}"/> is âsmallâ.</div>
</div>
<div class="line-block">
<div class="line"><strong>Method based on singular value decomposition</strong></div>
</div>
<div class="line-block">
<div class="line">The so-called <em>singular value decomposition</em> (SVD) of matrix
<img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/> reads:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/3147993e649908d7a704c4b2b921d1a3f00d39c8.svg" alt="\matr{\Psi} \quad = \quad \matr{U} \; \matr{S} \; \matr{V}^{\mbox{\scriptsize \textsf{T}}}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">where <img class="math" src="../../_images/math/5bd0f2ae0b6d9a508bd448d3943c7d1c3af5816f.svg" alt="\matr{U}~\in \Rset^{N \times N}"/> and
<img class="math" src="../../_images/math/8e95a7655bf36973a80f9a51b7c21de709964bc6.svg" alt="\matr{V}~\in \Rset^{P \times P}"/> are orthogonal matrices, and
<img class="math" src="../../_images/math/df369931110cb47abba57c6063dccd251f49ca32.svg" alt="\matr{S}~\in \Rset^{N \times P}"/> can be cast as:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/f4e35ad62d97b35e09a660b7b8c538498c0f431f.svg" alt="\begin{aligned}
    \matr{S} \quad = \quad \left(
    \begin{array}{c}
      \matr{S}_1 \\
      \matr{0} \\
    \end{array}
    \right)
  \end{aligned}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">In the previous equation, <img class="math" src="../../_images/math/19ceed47377e5904868b45be9e7f55a1a98f3176.svg" alt="\matr{S}_1~\in \Rset^{P \times P}"/>
is a diagonal matrix containing the singular values
<img class="math" src="../../_images/math/2763f94691cda3ad256d6f115e399a08cae728f3.svg" alt="\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_P &gt; 0"/> of
<img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/>.</div>
</div>
<div class="line-block">
<div class="line">It can be shown that the least squares solution is equal to:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/ce7d8e4fa34948fadd9b85f7659a8e45a10faf81.svg" alt="\begin{aligned}
    \widehat{\underline{a}} \quad = \quad \matr{V} \; \left( \begin{array}{c}
      \matr{S}_1^{-1} \\
      \matr{0}  \\
    \end{array}\right)
    \; \matr{U}^{\mbox{\scriptsize \textsf{T}}} \; \underline{y}
  \end{aligned}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">In practice it is not common to compute a âfullâ SVD as shown above.
Instead, it is often sufficient and more economical in terms of time
and memory to compute a <em>reduced</em> version of SVD. The latter reads:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/c5421f7f173ffff0a500310ae0fcce4bee7af7f4.svg" alt="\matr{\Psi} \quad = \quad \matr{U}_1 \; \matr{S}_1 \; \matr{V}^{\mbox{\scriptsize \textsf{T}}}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">where <img class="math" src="../../_images/math/d78d6543bbb5112b6be319a90cbfdba6bc989b16.svg" alt="\matr{U}_1"/> is obtained by extracting the <img class="math" src="../../_images/math/4c21bd0a8df01ae42f62d11fb29cb9ae23746161.svg" alt="P"/>
first columns of <img class="math" src="../../_images/math/bbc58ffa0f76fb66074b578369b05a7470cf7e91.svg" alt="\matr{U}"/>.</div>
</div>
<div class="line-block">
<div class="line">Note that it is also possible to perform SVD in case of a
rank-deficient matrix <img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/>. In this case the resulting
vector <img class="math" src="../../_images/math/a929c0c51ee4e28afc4a1d03c186cc2ba3eeb132.svg" alt="\widehat{\underline{a}}"/> corresponds to the <em>minimum
norm</em> least squares solution.</div>
</div>
<div class="line-block">
<div class="line">The computational cost of the method is proportional to
<img class="math" src="../../_images/math/08493922c203db0d22385131db11da5a8d8533d0.svg" alt="(NP^2 + P^3)"/> with a factor ranging from 4 to 10, depending on
the numerical scheme used to compute the SVD decomposition. This cost
is higher than those associated with the normal equations and with QR
factorization. However SVD is relevant insofar as it provides a very
valuable information, that is the singular values of matrix
<img class="math" src="../../_images/math/99103ae780106d2afeade68a379123a1984e8b1a.svg" alt="\matr{\Psi}"/>.</div>
</div>
<p><strong>Comparison of the methods</strong></p>
<p>Several conclusions may be drawn concerning the various methods
considered so far:</p>
<ul class="simple">
<li>If <img class="math" src="../../_images/math/5851ceefa52ef9354b501174914cf0f99cd15122.svg" alt="N \approx P"/>, normal equations and Householder QR
factorization require about the same computational work. If
<img class="math" src="../../_images/math/059b1ef0aa30e1e79aadd9911a91bbe76fe1dea3.svg" alt="N &gt;&gt; P"/>, then the QR approach requires about twice as much
work as normal equations.</li>
<li>However QR appears to be more accurate than normal equations, so it
should be almost always preferred in practice.</li>
<li>SVD is also robust but it reveals the most computationally expensive
scheme. Nonetheless the singular values are obtained as a by-product,
which may be particularly useful for analytical and computational
purposes.</li>
</ul>
<div class="topic">
<p class="topic-title first">API:</p>
<ul class="simple">
<li>See the available <a class="reference internal" href="../../user_manual/response_surface/functional_chaos_expansion.html#least-squares-methods"><span class="std std-ref">least squares methods</span></a>.</li>
<li>See <a class="reference internal" href="../../user_manual/response_surface/_generated/openturns.PenalizedLeastSquaresAlgorithm.html#openturns.PenalizedLeastSquaresAlgorithm" title="openturns.PenalizedLeastSquaresAlgorithm"><code class="xref py py-class docutils literal notranslate"><span class="pre">PenalizedLeastSquaresAlgorithm</span></code></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">References:</p>
<ul class="simple">
<li><ol class="first upperalpha">
<li>Bjorck, 1996, âNumerical methods for least squares problemsâ, SIAM Press, Philadelphia, PA.</li>
</ol>
</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="isoprobabilistic_transformation.html" title="Isoprobabilistic transformations"
             >next</a> |</li>
        <li class="right" >
          <a href="optimization_algorithm.html" title="Optimization Algorithms"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="numerical_methods.html" >Numerical methods</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2018 Airbus-EDF-IMACS-Phimeca.
      Last updated on Jan 01, 2018.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.1.
    </div>
  </body>
</html>